
Binary LCE = $LCE(y, t) = −tlog y − (1 − t) log 1 − y.$
y = pred
t = label

For multi-class:

![[Pasted image 20250306225047.png]]


![[Pasted image 20250126191807.png]]
y = pred
t = label
Cross-entropy solves the previous problem because it draws big distinctions between probabilities close to 0 or 1
![[Pasted image 20250418211846.png]]